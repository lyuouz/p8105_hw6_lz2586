---
title: "P8105_hw6_lz2586"
author: "Lyuou Zhang"
date: "11/25/2018"
output: 
  github_document:
    toc: true
---

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(ggcorrplot)
```



## problem 1

### data cleaning and create variables

```{r}
homicide <- read_csv('./data/homicide-data.csv') %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, state, sep = ', ')
  ) %>% 
  filter(city_state != 'Dallas, TX' & city_state != 'Phoenix, AZ' & city_state != 'Kansas City, MO' & city_state != 'Tulsa, AL') %>% 
  mutate(
    victim_age = as.numeric(victim_age),
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_race = ifelse(victim_race == 'White', 'white', 'non-white'),
    victim_race = as.factor(victim_race),
    victim_race = relevel(victim_race, ref = 'white'),
    victim_sex = fct_relevel(victim_sex, ref = 'Male')
  )

```


  
* Created new variables:  
  + `city_state`: combines city and state  
  + `resolved`: 1 = resolved ('Closed by arrest'), 0 = unresolved  
  + `race_cate`: race categorized as `white` and `non-white`, using `white` as the reference
* Filtered cities with no race data  

Note that after certain cities were filtered out, there are still "unknown" entries in `victim_sex` and `victim_race`.  

* `victim_race`: included "unknown" in the `non-white` category.  
* `victim_sex`: I have three options to deal with missing data:  
  + filter them before the analysis  
  + randomly assign them `Male` or `Female`  
  + because we only need the coefficient of non-white compared to white, I can just leave it alone for now 

```{r}
homicide %>% 
  filter(victim_sex == 'Unknown')
```

There are 560 rows whose victim_sex are missing. The dataset has `r nrow(homicide)` rows in total, so there are not a lot of missing data points. I'll leave it alone for now, which means I'll be using "Unknown" as a gender category in the regression.

### Logistic model for Baltimore

Filter `homicide` to get the data frame for Baltimore, MD

```{r}
baltimore <- homicide %>% 
  filter(city == 'Baltimore')

```

logistic model building for Baltimore: using resolved vs. unresolved as the outcome and victim age, sex and race as predictors. 

```{r}

logistic_baltimore <- baltimore %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = .,, family = binomial())

```

The output of glm has been saved in `logistic_baltimore`.

```{r}
# tidy the results for the logistic regression model for Baltimore
baltimore_results <- logistic_baltimore %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         conf_low = estimate - 1.96 * std.error,
         conf_high = estimate + 1.96 * std.error,
         OR_low = exp(conf_low),
         OR_high = exp(conf_high))

# knit into a table
baltimore_results %>% 
  select(term, log_OR = estimate, OR, OR_low, OR_high) %>% 
  knitr::kable()

```

The confidence intervals are computed using `mean + SE*1.96` or `mean - SE*1.96`. For Baltimore, the OR for non-white victim vs. white victim is 0.441. The confidence interval of the adjusted OR is (0.313, 0.620).  

### Logistic regression for all the cities

I'm going to write a function that wraps up model building, tidying results and computing OR and confidence intervals.

```{r}

logistic_function <- function(df){
  
  model = glm(resolved ~ victim_age + victim_race + victim_sex, data = df, family = binomial())
  
  tidy_results = model %>% broom::tidy() %>% 
    filter(term == 'victim_racenon-white') %>% 
    mutate(
      OR = exp(estimate),
        conf_low = estimate - 1.96 * std.error,
        conf_high = estimate + 1.96 * std.error,
        OR_low = exp(conf_low),
        OR_high = exp(conf_high)
    ) 
  
  tidy_results
}
```

I'll be using list columns with `nest()` because here `purrr::map` should work with "sub" datasets of each city_state.

```{r}
homicide_nest <- homicide %>% 
  select(city_state, resolved, victim_age, victim_sex, victim_race) %>% 
  group_by(city_state) %>%
  nest()
```

Using `map` to apply the function `logistic_function` to each city_state

```{r}
# applying function using map
homicide_model_results <- homicide_nest %>% 
  mutate(
    logistic_results = map(homicide_nest$data, logistic_function)
  ) %>% 
  select(-data) %>% 
  unnest()

```

Creating a plot that shows the estimated ORs and CIs for each city:

```{r}

homicide_model_results %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + geom_point() +
  geom_errorbar(aes(ymin = OR_low, ymax = OR_high)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))


```

This figure shows that the city with the smallest estimated OR is Boston, MA, and the largest OR is in Tampa, FL. There are only two cities whose ORs are larger than 1: Durham, NC and Tampa, FL, which means holding other variables constant, we will see increase in the odds of the victim being non-white vs. the victim being white. However, for most cities, being white will increase the odds of resolving the case. 

## Problem 2

Data import, cleaning and checking missing variables

```{r}
# data import and cleaning
birthwt <- read_csv('./data/birthweight.csv') %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  )

# checking missing variable
skimr::skim(birthwt)
# no missing variable

```

### Model building

Model building: Here are the things that I considered when I picked the indicators:

* literature shows that factors in this dataset that can affect birth weight include mother's race, mother's age, prenatal care, nutrition and smoking.  

* Babysex, head circumference, baby's leangth at birth are related to baby's "size". It makes sense that they are related to baby's weight.  

* As the baby's age grows, his or her weight will also grow. So gestational age might be related to birth weight too.  

* There is no variable that shows if the mom had access to prenatal care or her nutrition status. However, mom's race could be related to if she has access to healthcare, and her financial status which could further be related to her nutrition status.  

* For mom's age, there is evidence showing that the incidence of low birthweight is higher for mother under 18 or above 35. The range of mom's age in this dataset is `r range(birthwt$momage)`. So the relationship between mom's age and birth weight is probably not a linear one. I include mom's age because I want to see what the relationship will look like.  

* Smoking is associated with adverse pregnancy outcomes because smoking during pregnancy harms both the mother and the baby. Prenatal smoking is thought to account for 20~30% of cases of low birth weight.

Considering other biological and social factors that might be indicators or confounders, the variables to be used in the model are: babysex, bhead, blength, delwt, gaweeks, menarche, momage, mrace, and smoken  

To take a look at the correlations between variables, I can also create a correlation heatmap. However, this only works for numeric variables.

```{r}
# subset the data to only contain numeric variables:
# because pnumlbw and pnumsga are all 0, there's no need to include them
birthwt_num <- birthwt %>% 
  select_if(is.numeric) %>% 
  select(-pnumlbw, -pnumsga)

corr_wt <- round(cor(birthwt_num), 3)
ggcorrplot(corr_wt)

```

`blength` and `bhead` and `gaweeks` are positively correlated with birth weight. `smoken` is negatively correlated with birth weight.

```{r}
# model building
birthlm <- lm(bwt ~ babysex + bhead + blength + delwt + momage + gaweeks + menarche +  mrace + smoken, data = birthwt)

birthlm %>% 
  broom::tidy()

birthlm %>% 
  broom::glance()
```

From the results:  

* R2 = 0.714, which means about 71% of birth weight are explained by this model.  

* `babysex`, `bhead`, `blength`, `delwt`, `gaweeks`, `mrace2` (black), `mrace4` (Puerto Rican) and smoken are significantly associated with birth weight. Among these variables:  
  + `babysex` (female vs. male), `bhead`, `blength`, `delwt` and `gasweeks` are positively associated with birth weight.  
  + `mrace2` (black), `mrace4` (Puerto Rican) and smoken are negatively associated with birth weight.  
  + Asian is the only race that is not associated with birth weight.

The plot of predicted values vs. residuals.

```{r}
# add predictions and residuals
birthwt <- modelr::add_residuals(birthwt, birthlm)
birthwt <- modelr::add_predictions(birthwt, birthlm)

# residuals vs. predictions plot
birthwt %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point() +
  geom_smooth(se = FALSE)

```

Except for a few outliers, the residuals look randomly distributed across the range of the predicted values and around 0. 


Alternative model 1:

```{r}
model2 <- lm(bwt ~ blength + gaweeks, data = birthwt)

model2 %>% 
  broom::tidy()

model2 %>% 
  broom::glance()
```

In this model, both `blength` and `gaweeks` are significantly and positively associated with birth weight. R2 = 0.5769 and is smaller than the R2 in the previous model, which means compared to that model, model2 is not as well specified as in terms of independent variables.   

Alternative model 2:

```{r}
model3 <- lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthwt)

model3 %>% broom::tidy()

model3 %>% broom::glance()

```

In this model, bhead, blength and babysex are all significantly and positively associated with birth weight. For the interactions, bhead:babysex2 and blength:babysex2 are negatively associated with birth weight. bhead:blength:babysex2 is positively associated with birth weight. bhead:blength is the only variable that is not significant.


### Cross validation

```{r}
cv_df <- crossv_mc(birthwt, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

cv_df <- cv_df %>% 
  mutate(
    model1 = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + momage + gaweeks + menarche + mrace + smoken, data = birthwt)),
    model2 = map(train, ~lm(bwt ~ blength + gaweeks, data = birthwt)),
    model3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthwt))
  ) %>% 
  mutate(
    rmse1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y))
  )

cv_df %>% 
  select(starts_with('rmse')) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(
    model = str_replace(model, 'rmse', ''),
    model = fct_inorder(model)
  ) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```

Overall, model1, which is the model that I proposed, has the least rmse. Compared to the two other models, my model has more independent variables that could explain birth weight, so it's better specified. I think that is why the rmse is lower for this model.




